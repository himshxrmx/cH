Smart Attendance System
AI-Powered Classroom Engagement Detection (Cloud Hackathon Project)

ğŸ”— Live Demo: https://ch-gajd.onrender.com/

ğŸ“Œ Overview

Smart Attendance is an AI-powered classroom analytics system that detects student engagement using Facial Expression Recognition (FER).

The system analyzes classroom images in real-time, detects dominant emotions using a pre-trained AI model, and calculates overall engagement percentage. Results are stored securely in the cloud for tracking and analytics.

This project was built for a Cloud Hackathon, demonstrating integration of:

Cloud deployment

AI inference APIs

Backend APIs

Database storage

Real-time UI interaction

ğŸ§© Problem Statement
ğŸš¨ Problem

Traditional attendance systems:

Only record presence

Do not measure engagement

Cannot detect student focus levels

Lack real-time analytics

Teachers have no insight into:

How many students are attentive

Emotional classroom atmosphere

Engagement trends over time

âœ… Proposed Solution

We built a cloud-based AI system that:

Accepts classroom images

Uses Facial Expression Recognition (FER)

Detects emotions like:

Happy

Neutral

Surprise

Sad

Angry

Converts emotions into engagement metrics

Stores results in a cloud database

Provides analytics dashboard access

ğŸš€ Key Features

ğŸ¯ Real-time Facial Expression Recognition

ğŸ“Š Automatic Engagement Percentage Calculation

â˜ï¸ Cloud Deployment (Render)

ğŸ—„ MongoDB Atlas Cloud Storage

ğŸ” Secure API with Hugging Face Token

ğŸ–¼ Drag & Drop Image Upload

ğŸ“ˆ Dashboard-ready record endpoint

ğŸŒ™ Modern UI with theme toggle

âš¡ REST API based architecture

ğŸ— Technical Architecture
ğŸ” System Flow
User Uploads Image
        â†“
Frontend (HTML/CSS/JS)
        â†“
Node.js Backend (Express)
        â†“
Hugging Face AI Model API
        â†“
Emotion Prediction
        â†“
Engagement Calculation
        â†“
MongoDB Atlas Storage
        â†“
JSON Response to UI

ğŸ“Š Architecture Diagram (Logical View)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Frontend        â”‚
â”‚  (HTML/CSS/JS)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ HTTP Request
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Node.js Backend    â”‚
â”‚  Express + Multer   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ API Call
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hugging Face AI    â”‚
â”‚  ViT Emotion Model  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ Emotion Result
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MongoDB Atlas Cloud â”‚
â”‚ Engagement Records  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â˜ Cloud Hosting Details
Component	Cloud Provider
Backend Hosting	Render
Database	MongoDB Atlas
AI Inference	Hugging Face Cloud API
Frontend	Static (served via Render)
ğŸ§  What Hugging Face Does

We use the pre-trained model:

trpakov/vit-face-expression


It:

Accepts image input

Detects facial expression

Returns emotion predictions

Does NOT store any data

Your backend:

Converts emotion â†’ engagement

Saves data to MongoDB

ğŸ›  Detailed Tech Stack
ğŸ”¹ Frontend

HTML5

CSS3 (Modern UI)

JavaScript (Vanilla)

Fetch API

Drag & Drop API

ğŸ”¹ Backend

Node.js

Express.js

Multer (Image Upload Handling)

Axios (API calls)

dotenv (Environment variables)

ğŸ”¹ Database

MongoDB Atlas

Mongoose ODM

ğŸ”¹ AI Layer

Hugging Face Inference API

Vision Transformer (ViT) Model

ğŸ”¹ Cloud Infrastructure

Render Web Service

Environment Variables

Secure Token-based authentication

ğŸ“ Project Structure
Smart-Attendance/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ Record.js
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ analyze.js
â”‚   â”œâ”€â”€ server.js
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ dashboard.html
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ script.js
â”‚
â”œâ”€â”€ .env
â””â”€â”€ README.md

âš™ï¸ Environment Variables

Create a .env file:

MONGO_URI=your_mongodb_connection_string
HF_TOKEN=your_huggingface_token
PORT=3000

â–¶ï¸ Usage
1ï¸âƒ£ Clone Repository
git clone https://github.com/yourusername/smart-attendance.git
cd smart-attendance

2ï¸âƒ£ Install Backend Dependencies
cd backend
npm install

3ï¸âƒ£ Run Locally
node server.js


Server will run on:

http://localhost:3000

4ï¸âƒ£ Upload Image

Drag & Drop classroom image

Click Analyze

View engagement results

Data stored in MongoDB

ğŸ“Š API Endpoints
POST /analyze

Uploads image and returns engagement data

GET /records

Fetch all stored engagement records

ğŸ¯ Engagement Logic
Happy / Neutral / Surprise â†’ Engaged
Sad / Angry / Fear â†’ Not Engaged


Engagement % = (Engaged / Total Students) Ã— 100

(Current version processes one face per image)

ğŸ”’ Security Measures

HF Token stored in environment variables

MongoDB credentials secured

No sensitive data exposed in frontend

CORS configured

ğŸ“ˆ Future Improvements

Multi-face detection per image

Real-time webcam support

Engagement trend analytics graph

Role-based login system

Teacher dashboard

Classroom-wise data filtering

AWS/GCP deployment

ğŸ† Hackathon Highlights

Cloud-native deployment

AI inference integration

Database integration

REST API architecture

Scalable modular design

ğŸ‘¨â€ğŸ’» Author

Built for Cloud Hackathon 2026
Smart Attendance â€“ AI Powered Engagement Detection

